{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import string\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from torch.utils.tensorboard import  SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.functional\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-25T15:04:36.321531Z",
     "iopub.execute_input": "2023-06-25T15:04:36.321794Z",
     "iopub.status.idle": "2023-06-25T15:04:49.249442Z",
     "shell.execute_reply.started": "2023-06-25T15:04:36.321770Z",
     "shell.execute_reply": "2023-06-25T15:04:49.248480Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=400, beta_start=1e-4, beta_end=0.02, img_size=64, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    def sample(self, model, n, labels, cfg_scale=3):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                predicted_noise = model(x, t, labels)\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-25T15:04:49.251196Z",
     "iopub.execute_input": "2023-06-25T15:04:49.251544Z",
     "iopub.status.idle": "2023-06-25T15:04:49.268184Z",
     "shell.execute_reply.started": "2023-06-25T15:04:49.251513Z",
     "shell.execute_reply": "2023-06-25T15:04:49.267267Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-25T15:04:49.269585Z",
     "iopub.execute_input": "2023-06-25T15:04:49.270144Z",
     "iopub.status.idle": "2023-06-25T15:04:49.281605Z",
     "shell.execute_reply.started": "2023-06-25T15:04:49.270111Z",
     "shell.execute_reply": "2023-06-25T15:04:49.280661Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-25T15:04:49.286153Z",
     "iopub.execute_input": "2023-06-25T15:04:49.286477Z",
     "iopub.status.idle": "2023-06-25T15:04:49.296405Z",
     "shell.execute_reply.started": "2023-06-25T15:04:49.286453Z",
     "shell.execute_reply": "2023-06-25T15:04:49.295585Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MyUNetConditioned(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256,num_classes=None, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.init = DoubleConv(c_in,64)\n",
    "\n",
    "        self.maxpool_conv1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(64, 64, residual=True),\n",
    "            DoubleConv(64, 128),\n",
    "        )\n",
    "        self.emb_layer1 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim,128),\n",
    "        )\n",
    "        self.sa1 = nn.Sequential(\n",
    "            SelfAttention(128,32)\n",
    "        )\n",
    "\n",
    "        self.maxpool_conv2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(128, 128, residual=True),\n",
    "            DoubleConv(128, 256),\n",
    "        )\n",
    "        self.emb_layer2 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim,256),\n",
    "        )\n",
    "        self.sa1_1 = nn.Sequential(\n",
    "            SelfAttention(256,16)\n",
    "        )\n",
    "\n",
    "        self.maxpool_conv2_1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(256, 256, residual=True),\n",
    "            DoubleConv(256, 256),\n",
    "        )\n",
    "        self.emb_layer2_1 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim,256),\n",
    "        )\n",
    "\n",
    "\n",
    "        #Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            DoubleConv(256, 512),\n",
    "            DoubleConv(512, 512),\n",
    "            DoubleConv(512, 256),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.up_conv3 = nn.Sequential(\n",
    "            DoubleConv(512, 512, residual=True),\n",
    "            DoubleConv(512, 128),\n",
    "        )\n",
    "        self.emb_layer3 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim,128),\n",
    "        )\n",
    "        self.sa2 = nn.Sequential(\n",
    "            SelfAttention(128,16)\n",
    "        )\n",
    "\n",
    "        self.up3_1 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.up_conv3_1 = nn.Sequential(\n",
    "            DoubleConv(256, 256, residual=True),\n",
    "            DoubleConv(256, 64),\n",
    "        )\n",
    "        self.emb_layer3_1 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim,64),\n",
    "        )\n",
    "        self.sa1_2 = nn.Sequential(\n",
    "            SelfAttention(64,32)\n",
    "        )\n",
    "\n",
    "        self.up4 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.up_conv4 = nn.Sequential(\n",
    "            DoubleConv(128, 128, residual=True),\n",
    "            DoubleConv(128, 64),\n",
    "        )\n",
    "        self.emb_layer4 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim,64),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.exit = nn.Conv2d(64,c_out,1)\n",
    "\n",
    "        if num_classes is not None:\n",
    "            self.label_emb = nn.Embedding(num_classes, time_dim)\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2, device=self.device).float() / channels))\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t, y):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "\n",
    "        if y is not None:\n",
    "            t += self.label_emb(y)\n",
    "\n",
    "        x = self.init(x)\n",
    "\n",
    "\n",
    "        x1 = self.maxpool_conv1(x)\n",
    "        emb1 = self.emb_layer1(t)[:, :, None, None].repeat(1, 1, x1.shape[-2], x1.shape[-1])\n",
    "        x1 = x1 + emb1\n",
    "        x1 = self.sa1(x1)\n",
    "\n",
    "\n",
    "        x2 = self.maxpool_conv2(x1)\n",
    "        emb2 = self.emb_layer2(t)[:, :, None, None].repeat(1, 1, x2.shape[-2], x2.shape[-1])\n",
    "        x2 = x2 + emb2\n",
    "        x2 = self.sa1_1(x2)\n",
    "\n",
    "\n",
    "        x2_1 = self.maxpool_conv2_1(x2)\n",
    "        emb2_1 = self.emb_layer2_1(t)[:, :, None, None].repeat(1, 1, x2_1.shape[-2], x2_1.shape[-1])\n",
    "        x2_1 = x2_1 + emb2_1\n",
    "\n",
    "        #Bottleneck\n",
    "        bottleneck = self.bottleneck(x2_1)\n",
    "\n",
    "\n",
    "        x3 = self.up3(bottleneck)\n",
    "        x3 = torch.cat((x3, x2), dim=1)\n",
    "        x3 = self.up_conv3(x3)\n",
    "        emb3 = self.emb_layer3(t)[:, :, None, None].repeat(1, 1, x3.shape[-2], x3.shape[-1])\n",
    "        x3 = x3 + emb3\n",
    "        x3 = self.sa2(x3)\n",
    "\n",
    "\n",
    "        x3_1 = self.up3_1(x3)\n",
    "        x3_1 = torch.cat((x3_1, x1), dim=1)\n",
    "        x3_1 = self.up_conv3_1(x3_1)\n",
    "        emb3_1 = self.emb_layer3_1(t)[:, :, None, None].repeat(1, 1, x3_1.shape[-2], x3_1.shape[-1])\n",
    "        x3_1 = x3_1 + emb3_1\n",
    "        x3_1 = self.sa1_2(x3_1)\n",
    "        \n",
    "\n",
    "        x4 = self.up3_1(x3_1)\n",
    "        x4 = torch.cat((x4, x), dim=1)\n",
    "        x4 = self.up_conv4(x4)\n",
    "        emb4 = self.emb_layer4(t)[:, :, None, None].repeat(1, 1, x4.shape[-2], x4.shape[-1])\n",
    "        x4 = x4 + emb4\n",
    "        \n",
    "\n",
    "        return self.exit(x4)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-25T15:04:49.300144Z",
     "iopub.execute_input": "2023-06-25T15:04:49.300427Z",
     "iopub.status.idle": "2023-06-25T15:04:49.327578Z",
     "shell.execute_reply.started": "2023-06-25T15:04:49.300405Z",
     "shell.execute_reply": "2023-06-25T15:04:49.326528Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n = 10  # Numero di immagini da generare per ogni etichetta\n",
    "device = device\n",
    "model = MyUNetConditioned(num_classes=22).to(device)\n",
    "\n",
    "ckpt = torch.load(r\"/kaggle/input/ema-ckpt-final/ema_ckpt.pt\")\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "diffusion = Diffusion(img_size=64, device=device)\n",
    "\n",
    "save_dir = \"generated_images_1\"  # Cartella di destinazione per le immagini generate\n",
    "os.makedirs(save_dir, exist_ok=True)  # Crea la cartella se non esiste\n",
    "\n",
    "# Definisci il dizionario con le corrispondenze tra chiavi e label\n",
    "dizionario = {\n",
    "    \"00000\": 0,\n",
    "    \"00001\": 1,\n",
    "    \"00010\": 2,\n",
    "    \"00011\": 3,\n",
    "    \"00101\": 4,\n",
    "    \"00111\": 5,\n",
    "    \"01001\": 6,\n",
    "    \"01010\": 7,\n",
    "    \"01011\": 8,\n",
    "    \"01101\": 9,\n",
    "    \"01111\": 10,\n",
    "    \"10000\": 11,\n",
    "    \"10001\": 12,\n",
    "    \"10010\": 13,\n",
    "    \"10011\": 14,\n",
    "    \"10101\": 15,\n",
    "    \"10111\": 16,\n",
    "    \"11000\": 17,\n",
    "    \"11001\": 18,\n",
    "    \"11011\": 19,\n",
    "    \"11101\": 20,\n",
    "    \"11111\": 21\n",
    "}\n",
    "letters = string.ascii_uppercase  # Lettere dell'alfabeto\n",
    "n = 10\n",
    "with open(\"/kaggle/input/testtxt/test.txt\", \"r\") as file:\n",
    "    for riga in file:\n",
    "        riga = riga.strip()\n",
    "        if riga:\n",
    "            elementi = riga.split(\";\")\n",
    "            if len(elementi) == 2:\n",
    "                nome_immagine, chiave = elementi\n",
    "                if chiave in dizionario:\n",
    "                    label = dizionario[chiave]\n",
    "                    print(chiave)\n",
    "                    y = torch.Tensor([label] * n).long().to(device)\n",
    "                    x = diffusion.sample(model, n, y, cfg_scale=3)\n",
    "                    for i in range(n):                        \n",
    "                        image = x[i].cpu().permute(1, 2, 0).numpy()\n",
    "                        file_name = f\"{nome_immagine}_{letters[i]}.jpg\"\n",
    "                        save_path = os.path.join(save_dir, file_name)\n",
    "                        plt.imsave(save_path, image) \n",
    "                else:\n",
    "                    print(f\"La chiave {chiave} non è presente nel dizionario.\")\n",
    "            else:\n",
    "                print(f\"La riga {riga} non ha il formato corretto.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-25T15:04:49.329177Z",
     "iopub.execute_input": "2023-06-25T15:04:49.329826Z",
     "iopub.status.idle": "2023-06-25T15:21:57.910620Z",
     "shell.execute_reply.started": "2023-06-25T15:04:49.329792Z",
     "shell.execute_reply": "2023-06-25T15:21:57.909582Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
